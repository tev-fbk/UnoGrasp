<!DOCTYPE html>
<html>
<head>
  <script id="Cookiebot" src="https://consent.cookiebot.com/uc.js" data-cbid="9f55e120-3e25-41ae-bfeb-361a726c0a09" type="text/javascript" async></script>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-JNN7F7HDFD"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'G-JNN7F7HDFD');
  </script>
  
  <meta charset="utf-8">
  <meta name="description"
        content="Obstruction reasoning for robotic grasping">
  <meta name="keywords" content="FreeGrasp, Language Vision Robotic Grasping">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <title>Obstruction reasoning for robotic grasping</title>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      setTimeout(function () {
        bulmaCarousel.attach('#results-carousel', {
          slidesToScroll: 1,
          slidesToShow: 1,
          infinite: true,
          autoplay: true
        });
      }, 500);
    });
  </script>

  <!-- Global site tag (gtag.js) - Google Analytics -->
<!-- Google tag (gtag.js) -->


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->
  <link rel="icon" href="./static/image/icon.png">


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <!-- <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script> -->

<style>
/* 通用箭头样式 */
.swiper-btn-prev-1, .swiper-btn-next-1,
.swiper-btn-prev-2, .swiper-btn-next-2,
.swiper-btn-prev-3, .swiper-btn-next-3 {
  width: 30px;
  height: 30px;
  background: rgba(0,0,0,0.5);
  border-radius: 50%;
  position: absolute;
  top: 50%;
  transform: translateY(-50%);
  z-index: 10;
  cursor: pointer;
}

/* 左箭头位置 */
.swiper-btn-prev-1, .swiper-btn-prev-2, .swiper-btn-prev-3 {
  left: 10px;
}

/* 右箭头位置 */
.swiper-btn-next-1, .swiper-btn-next-2, .swiper-btn-next-3 {
  right: 10px;
}

/* 箭头符号 */
.swiper-btn-prev-1::after,
.swiper-btn-prev-2::after,
.swiper-btn-prev-3::after {
  content: "<";
  font-size: 20px;
  color: white;
  position: absolute;
  left: 8px;
  top: 2px;
}

.swiper-btn-next-1::after,
.swiper-btn-next-2::after,
.swiper-btn-next-3::after {
  content: ">";
  font-size: 20px;
  color: white;
  position: absolute;
  left: 10px;
  top: 2px;
}
</style>


</head>





<body>
    <nav class="navbar" role="navigation" aria-label="main navigation">
        <div class="navbar-brand">
            <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
            </a>
        </div>

        <div class="navbar-menu">
            <div class="navbar-start" style="flex-grow: 1; justify-content: center">

                <div class="navbar-item has-dropdown is-hoverable">
                    <a class="navbar-link"> Previous Research </a>
                    <div class="navbar-dropdown">
                        <a class="navbar-item" href="https://tev-fbk.github.io/FreeGrasp/" target="_blank">
                            FreeGrasp (IROS 2025)
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <!-- <h1 class="title is-1 publication-title">Obstruction reasoning for robotic grasping</h1> -->
          <h1 class="title is-1 publication-title">
            <!-- <img src="./static/image/icon.png" alt="Robot Arm" style="width: 150px; height: auto; vertical-align: middle; margin-right: 10px;"> -->
            Obstruction reasoning for robotic grasping
          </h1>          
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://tev.fbk.eu/team/runyu-jiao">Runyu Jiao</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=aGhFCssAAAAJ&hl=en&oi=ao">Matteo Bortolon</a><sup>1</sup>,
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=EOU10lkAAAAJ&hl=en&oi=ao">Francesco Giuliari</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://tev.fbk.eu/team/alice-fasoli">Alice Fasoli</a><sup>1</sup>,</span>
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=8u6dho8AAAAJ&hl=en&oi=ao">Sergio Povoli</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://gfmei.github.io/">Guofeng Mei</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.yimingwang.it/">Yiming Wang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://fabiopoiesi.github.io/">Fabio Poiesi</a><sup>1</sup>
            </span>
          </div>


          <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Fondazione Bruno Kessler,</span>
              <span class="author-block"><sup>2</sup>University of Trento</span>
          </div>

          <!-- Institution logos -->
          <div class="has-text-centered" style="margin-top: 10px;">
              <img src="static/image/fbk.png" 
                  alt="FBK Logo"
                  style="height: 58px; margin-right: 20px; vertical-align: middle;">

              <img src="static/image/unitn.png" 
                  alt="University of Trento Logo"
                  style="height: 58px; vertical-align: middle;">
          </div>

          <div class="has-text-centered" style="font-size: 1.2rem; font-weight: bold;">
            <p>CVPR 2026</p>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2511.23186"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              <!-- </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2503.13082"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=-2Mqtk0ABqQ"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (soon)</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data (soon)</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<hr>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">

      <!-- 标题 + 图标 -->
      <h2 class="title has-text-centered tight-title">
        <img src="static/image/icon.png" 
            style="width: 100px; vertical-align: middle; margin-right: 8px;">
        Not only <span style="color:#1e88e5;">spatial reasoning</span> 
        but also <span style="color:#B0ACE0;">obstruction reasoning</span>
      </h2>

      <br>
      <!-- Teaser 图片 -->
      <img 
        src="./static/image/teaser.jpg" 
        alt="Teaser Image" 
        style="width: 100%; height: auto;"
      >

      <!-- 图片下方的介绍文本 -->
      <h2 class="subtitle" style="text-align: justify;">
        UNOGrasp performs multi-step obstruction reasoning for robotic grasping in cluttered scenes. Given an RGB-D image and
        a natural-language goal (e.g., grasp the white iphone box), UNOGrasp reasons and grounds spatial information to infer the
        sequence of steps to unobstruct a requested object. We also introduce UNOBench to comprehensively benchmark obstruction reasoning.
      </h2>

    </div>
  </div>
</section>


<hr>

<section class="hero is-small" >
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Successful robotic grasping in cluttered environments not only requires a model to visually ground a target object but also to reason about obstructions that must be cleared beforehand. 
            While current vision-language embodied reasoning models show emergent spatial understanding, they remain limited in terms of obstruction reasoning and accessibility planning.
            To bridge this gap, we present UNOGrasp, a learning-based vision-language model capable of performing visually-grounded obstruction reasoning to infer the sequence of actions needed to <ins style="text-decoration: underline; text-decoration-color: #048000; text-decoration-thickness: 3px;">uno</ins>bstruct the path and <ins style="text-decoration: underline; text-decoration-color: #ff8c00; text-decoration-thickness: 3px;">grasp</ins> the target object.
            We devise a novel multi-step reasoning process based on obstruction paths originated by the target object. 
            We anchor each reasoning step with obstruction-aware visual cues to incentivize reasoning capability.
            UNOGrasp combines supervised and reinforcement finetuning through verifiable reasoning rewards.
            Moreover, we construct UNOBench, a large-scale dataset for both training and <ins style="text-decoration: underline; text-decoration-color: #0000ff; text-decoration-thickness: 3px;">bench</ins>marking, based on MetaGraspNetV2, with over 100k obstruction paths annotated by humans with obstruction ratios, contact points, and natural-language instructions. 
            Extensive experiments and real-robot evaluations show that UNOGrasp significantly improves obstruction reasoning and grasp success across both synthetic and real-world environments, outperforming generalist and proprietary alternatives. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<hr>

<!-- Benchmark Section -->
<section class="Section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <!-- <div class="column is-full-width"> -->
      <div style="text-align: center;">
        <h2 class="title is-3">Benchmark: UNOBench</h2>
        <img src="./static/image/benchmark.jpg" alt="Architecture of FreeGrasp" />
        <div class="content has-text-justified" style="margin-top: 2rem;">
          <p>
           UNOBench features two unique characteristics: (i) human-annotated free-form language instructions about objects in cluttered
           bins, and (ii) per-bin obstruction graphs for grounded spatial reasoning. Human annotators through the Prolific platform were involved to
           refine the initial GPT-4o generated annotations. UNOBench features three levels of difficulty and introduces novel evaluation metrics.          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<hr>
<!-- Method Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <!-- <div class="column is-full-width"> -->
      <div style="text-align: center;">
        <h2 class="title is-3">Method: UNOGrasp</h2>
        <img src="./static/image/method.jpg" alt="Architecture of FreeGrasp" />
        <div class="content has-text-justified" style="margin-top: 2rem;">
            UNOGrasp is a VLM trained through supervised fine (SFT) on UNOBench to learn structured obstruction-path reasoning, and
            through GRPO-based reinforcement finetuning (RFT) to further boost its reasoning ability using outcome-driven IoU and format rewards.
            During inference, given an RGB image and a target object as language instruction, UNOGrasp reasons over multiple obstruction paths
            (&lt;think> traces) and directly outputs the sequence of actions (&lt;answer>) required to remove obstructions and grasp the target.
        </div>
      </div>
    </div>
  </div>
</section>
<hr>

<section class="hero is-light is-small"> <!-- Use 'hero' to extend background fully -->
  <div class="hero-body"> <!-- Ensures the background fills the full width -->
    <div class="container"> <!-- Remove 'is-max-desktop' to allow full width content -->

      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Real-world Demo</h2>
          <div class="publication-video">
            <iframe width="560" height="315" src="https://www.youtube.com/embed/-2Mqtk0ABqQ?si=ibEpvvowv3oh6sVu" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
          </div>
        </div>
      </div>
      <!--/ Paper video. -->

    </div>
  </div>
</section>

<hr>

<!-- Qualitative Results Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div style="text-align: center;">

        <!-- Section Title -->
        <h2 class="title is-3">Qualitative Results</h2>

        <!-- Description ABOVE image -->
<div class="caption-container">
    <h3 class="caption-title">
        Qualitative Results under different splits. (SR-F1 / MP_NED) scores are reported at the bottom of each image.
    </h3>
</div>

        <!-- Image -->
        <img src="static/image/obstruction_vis.png" alt="Occlusion Graph Examples" style="width: 80%; height: auto; margin-top: 10px;" />

      </div>
    </div>
  </div>
</section>
                
<section class="hero is-small" style="background-color: white; padding: 20px 0;">
  <div class="hero-body">
    <div class="container">

      <h2 class="title is-3 has-text-centered">More examples</h2>

      <!-- <p class="has-text-left" style="font-size: 1rem; margin-bottom: 15px;">
        FreeGraspData is built upon MetaGraspNetV2...
      </p> -->

      <!-- ========== ROW 1 ========== -->
      <!-- Row 1 -->
      <div class="swiper swiper-container swiper-row-1" style="margin-bottom: 30px;">
        <div class="swiper-wrapper">
          <div class="swiper-slide"><img src="static/image/1vis.jpg" /></div>
          <div class="swiper-slide"><img src="static/image/2vis.jpg" /></div>
          <div class="swiper-slide"><img src="static/image/3vis.jpg" /></div>
          <div class="swiper-slide"><img src="static/image/4vis.jpg" /></div>
        </div>
        <div class="swiper-btn-prev-1"></div>
        <div class="swiper-btn-next-1"></div>
        <div class="swiper-pag-1"></div>
      </div>


      <!-- Row 2 -->
      <div class="swiper swiper-container swiper-row-2" style="margin-bottom: 30px;">
        <div class="swiper-wrapper">
          <div class="swiper-slide"><img src="static/image/5vis.jpg" /></div>
          <div class="swiper-slide"><img src="static/image/6vis.jpg" /></div>
          <div class="swiper-slide"><img src="static/image/7vis.jpg" /></div>
          <div class="swiper-slide"><img src="static/image/8vis.jpg" /></div>
        </div>
        <div class="swiper-btn-prev-2"></div>
        <div class="swiper-btn-next-2"></div>
        <div class="swiper-pag-2"></div>
      </div>

      <!-- Row 3 -->
      <div class="swiper swiper-container swiper-row-3">
        <div class="swiper-wrapper">
          <div class="swiper-slide"><img src="static/image/9vis.jpg" /></div>
          <div class="swiper-slide"><img src="static/image/10vis.jpg" /></div>
          <div class="swiper-slide"><img src="static/image/11vis.jpg" /></div>
          <div class="swiper-slide"><img src="static/image/12vis.jpg" /></div>
        </div>
        <div class="swiper-btn-prev-3"></div>
        <div class="swiper-btn-next-3"></div>
        <div class="swiper-pag-3"></div>
      </div>

      <!-- <p class="has-text-centered" style="font-size:0.9rem;margin-top:10px;">
        Examples of FreeGraspData at different task difficulties...
      </p> -->

    </div>
  </div>
</section>

<hr>

<!-- Swiper.js Dependency -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/swiper@10/swiper-bundle.min.css">
<script src="https://cdn.jsdelivr.net/npm/swiper@10/swiper-bundle.min.js"></script>


<!-- <section class="hero is-small" style="background-color: white; padding: 20px 0;">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-4 has-text-centered">Real-world setup</h2> 
      
      <div class="image-container">
        <img src="static/images/real-dataset.png" 
             alt="Grounding open-vocabulary object names and attributes" 
             style="width: 60%; height: auto; display: block; margin: 10px auto;" />
        <h2 class="subtitle has-text-centered" style="font-size: 0.9rem;">
          Samples from real-world experiments for different task difficulties.<br>
          <span style="color: rgb(255, 230, 0); font-size: 1.3em;">&#9733;</span> indicates the user-described target object, and <span style="color: rgb(4, 128, 0); font-size: 0.8em;">&#128994;</span> is/are the GT object(s) to pick.
        </h2>
      </div>

    </div>
  </div>
</section> -->


<!-- <hr> -->


<!--
<section class="section">
  <div class="container" style="max-width: 100%;">

    <div class="columns is-centered">
      <div class="column is-full has-text-centered">
        <h2 class="title is-3">Example of the complete method</h2>

        <div class="has-text-centered">
          <img src="./static/images/method_vis.png"
          alt="Method Visualization"
          style="max-width: 80%; width: auto; height: auto; display: block; margin: 0 auto;" />
        </div>
        <br/>
      </div>
    </div>

  </div>
</section>
-->

<section class="hero is-small" style="background-color: white; padding: 20px 0;">
  <div class="container" style="max-width: 80%;"> <!-- Matches previous section -->

    <!-- Related Links Section -->
    <div class="columns is-centered">
      <div class="column is-full has-text-left"> <!-- Full width & centered text -->
        <h2 class="title is-3">Related links</h2>

        <div class="content has-text-left" style="margin: 0 auto; max-width: 80%;">
          <p>
            Many excellent works have collectively contributed to our work.
          </p>
          <p>
            [1] <a href="https://tev-fbk.github.io/FreeGrasp/">Jiao, Runyu, et al. "Free-form language-based robotic reasoning and grasping." IROS. 2025.</a>
          </p>
          <p>
            [2] <a href="https://github.com/QwenLM/Qwen3-VL">Bai, Shuai, et al. "Qwen2.5-VL Technical Report." arXiv. 2025.</a>
          </p>
          <p>
            [3] <a href="https://github.com/om-ai-lab/VLM-R1">Shen, Haozhan, “VLM-R1: A Stable and Generalizable R1-style Large Vision-Language Model.” arXiv. 2025.</a>
          </p>
          <p>
            [4] <a href="https://arxiv.org/abs/2510.03342">Gemini Robotics Team, “Gemini Robotics 1.5: Pushing the Frontier of Generalist Robots with Advanced Embodied Reasoning, Thinking, and Motion Transfer.” arXiv. 2025.</a>
          </p>
          <p>
            [5] <a href="https://github.com/maximiliangilles/MetaGraspNet">Gilles, Maximilian, et al. "MetaGraspNetV2: All-in-One Dataset Enabling Fast and Reliable Robotic Bin Picking via Object Relationship Reasoning and Dexterous Grasping." TASE. 2024.</a>
          </p>
        </div>
      </div>
    </div>
    <!--/ Related Links Section -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{jiao2025obstruction,
  author = {Runyu Jiao and Matteo Bortolon and Francesco Giuliari and Alice Fasoli and Sergio Povoli and Guofeng Mei and Yiming Wang and Fabio Poiesi},
  title = {Obstruction reasoning for robotic grasping},
  year = {2025},
  eprint = {arXiv:2511.23186},
  note = {arXiv preprint}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
      <div class="content has-text-centered">
          <!-- Link to Paper -->
          <a class="icon-link" href="https://arxiv.org/abs/2511.23186" target="_blank" title="View Paper on arXiv">
              <i class="fas fa-file-pdf fa-2x"></i>
          </a>
          <!-- Link to GitHub -->
          <a class="icon-link" class="external-link" href="" target="_blank"
             title="View Project on GitHub">
              <i class="fab fa-github fa-2x"></i>
          </a>
      </div>
      <div class="columns is-centered" style="margin-top: 20px;">
          <div class="column is-8">
              <div class="content has-text-centered">
                  <p>
                      This website is licensed under a
                      <a href="http://creativecommons.org/licenses/by-sa/4.0/" rel="license" target="_blank">
                          Creative Commons Attribution-ShareAlike 4.0 International License
                      </a>.
                  </p>
                  <p>
                      Template adapted from
                      <a href="https://github.com/nerfies/nerfies.github.io" target="_blank">Nerfies</a>.
                  </p>
              </div>
          </div>
      </div>
  </div>
</footer>

<script>
new Swiper('.swiper-row-1', {
  navigation: {
    nextEl: '.swiper-btn-next-1',
    prevEl: '.swiper-btn-prev-1',
  },
  pagination: {
    el: '.swiper-pag-1',
    clickable: true,
  }
});

new Swiper('.swiper-row-2', {
  navigation: {
    nextEl: '.swiper-btn-next-2',
    prevEl: '.swiper-btn-prev-2',
  },
  pagination: {
    el: '.swiper-pag-2',
    clickable: true,
  }
});

new Swiper('.swiper-row-3', {
  navigation: {
    nextEl: '.swiper-btn-next-3',
    prevEl: '.swiper-btn-prev-3',
  },
  pagination: {
    el: '.swiper-pag-3',
    clickable: true,
  }
});
</script>


</body>

</html>
